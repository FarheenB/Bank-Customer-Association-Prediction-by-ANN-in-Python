{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2782,
     "status": "ok",
     "timestamp": 1586428376541,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "VYP9cQTWbzuI",
    "outputId": "38e3588f-f2e3-436b-bdc5-2967d495155c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2780,
     "status": "ok",
     "timestamp": 1586428376541,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "38vKGE6Nb2RR",
    "outputId": "2abeb945-135e-460f-99e9-9967abe198d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2775,
     "status": "ok",
     "timestamp": 1586428376542,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "-M1KboxFb6OO",
    "outputId": "c7b742e2-7afb-4fb9-c6b4-ffeb3c4812f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619 'France' 0 42 2 0.0 1 1 1 101348.88]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to escape from onehotencoding trap\n",
    "X=X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2768,
     "status": "ok",
     "timestamp": 1586428376543,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ZcxwEon-b8nV",
    "outputId": "9c88c069-f799-4e3b-be4b-24d8e17611fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 619 ... 1 1 101348.88]\n",
      " [0.0 1.0 608 ... 0 1 112542.58]\n",
      " [0.0 0.0 502 ... 1 0 113931.57]\n",
      " ...\n",
      " [0.0 0.0 709 ... 0 1 42085.58]\n",
      " [1.0 0.0 772 ... 1 0 92888.52]\n",
      " [0.0 0.0 792 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 619, 0, 42, 2, 0.0, 1, 1, 1, 101348.88], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2760,
     "status": "ok",
     "timestamp": 1586428376544,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "De3UsJwXdfMz",
    "outputId": "dde0e114-7250-42b5-d54d-047faebba5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57873591 -0.57380915 -0.32622142 ...  0.64609167  0.97024255\n",
      "   0.02188649]\n",
      " [-0.57873591  1.74273971 -0.44003595 ... -1.54776799  0.97024255\n",
      "   0.21653375]\n",
      " [-0.57873591 -0.57380915 -1.53679418 ...  0.64609167 -1.03067011\n",
      "   0.2406869 ]\n",
      " ...\n",
      " [-0.57873591 -0.57380915  0.60498839 ... -1.54776799  0.97024255\n",
      "  -1.00864308]\n",
      " [ 1.72790383 -0.57380915  1.25683526 ...  0.64609167 -1.03067011\n",
      "  -0.12523071]\n",
      " [-0.57873591 -0.57380915  1.46377078 ...  0.64609167 -1.03067011\n",
      "  -1.07636976]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "#input dim 11 output dim 6\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with dropout to reduce overfitting\n",
    "ann.add(tf.keras.layers.Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "#input dim 6 output dim 6\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with dropout to reduce overfitting\n",
    "ann.add(tf.keras.layers.Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "#input dim 6 output dim 1\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31750,
     "status": "ok",
     "timestamp": 1586428405580,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nHZ-LKv_ZRb3",
    "outputId": "6a90f176-803d-4b03-e65f-c05bda6f519c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.5811 - accuracy: 0.7049\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4910 - accuracy: 0.7945\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4683 - accuracy: 0.7989\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4545 - accuracy: 0.8031s - loss: 0.4551 - accuracy: 0.80\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.80 - 0s 30us/sample - loss: 0.4473 - accuracy: 0.8058\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4434 - accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4397 - accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.4342 - accuracy: 0.8126\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.4311 - accuracy: 0.8144\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.4288 - accuracy: 0.8159\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.4239 - accuracy: 0.8211\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4223 - accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4215 - accuracy: 0.8191\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4216 - accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4210 - accuracy: 0.8190\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4166 - accuracy: 0.8215\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.82 - 0s 31us/sample - loss: 0.4150 - accuracy: 0.8210\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4156 - accuracy: 0.8185\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4119 - accuracy: 0.8204\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4126 - accuracy: 0.8207\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4103 - accuracy: 0.8236\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4138 - accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4125 - accuracy: 0.8216\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4114 - accuracy: 0.8196\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4069 - accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4074 - accuracy: 0.8204\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.4084 - accuracy: 0.8190\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.4070 - accuracy: 0.8181\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4067 - accuracy: 0.8229\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.4001 - accuracy: 0.8250\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4039 - accuracy: 0.8191\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4063 - accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4015 - accuracy: 0.8198\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4046 - accuracy: 0.8191s - loss: 0.3990 - accuracy: 0.\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4034 - accuracy: 0.8227\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3989 - accuracy: 0.8227\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4025 - accuracy: 0.8216\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4052 - accuracy: 0.8188\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4021 - accuracy: 0.8170\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4057 - accuracy: 0.8199\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4006 - accuracy: 0.8210\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4001 - accuracy: 0.8215\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3983 - accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4011 - accuracy: 0.8210\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.4018 - accuracy: 0.8185\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.4006 - accuracy: 0.8196\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.4002 - accuracy: 0.8213\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.4002 - accuracy: 0.8223\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.4033 - accuracy: 0.8184\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.4032 - accuracy: 0.8190\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4032 - accuracy: 0.8204\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4021 - accuracy: 0.8211\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3990 - accuracy: 0.8192\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.4007 - accuracy: 0.8201\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.4021 - accuracy: 0.8206\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.4017 - accuracy: 0.8213s - loss: 0.4041 - accuracy: 0.\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3982 - accuracy: 0.8226\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3970 - accuracy: 0.8202\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3986 - accuracy: 0.8200\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3964 - accuracy: 0.8207\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3973 - accuracy: 0.8226\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.4006 - accuracy: 0.8205\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3986 - accuracy: 0.8245s - loss: 0.4069 - accuracy: \n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3962 - accuracy: 0.8225\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3955 - accuracy: 0.8213\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3948 - accuracy: 0.8246\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3964 - accuracy: 0.8217\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3954 - accuracy: 0.8231\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.4017 - accuracy: 0.8195\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3961 - accuracy: 0.8216\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3977 - accuracy: 0.8249\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3947 - accuracy: 0.8217\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3989 - accuracy: 0.8241\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3950 - accuracy: 0.8239\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3963 - accuracy: 0.8198\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3990 - accuracy: 0.8225\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3985 - accuracy: 0.8229\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3979 - accuracy: 0.8235\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3923 - accuracy: 0.8240\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3952 - accuracy: 0.8224\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3951 - accuracy: 0.8223\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3965 - accuracy: 0.8215\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3956 - accuracy: 0.8232\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3936 - accuracy: 0.8239\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3929 - accuracy: 0.8240\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3988 - accuracy: 0.8214\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3965 - accuracy: 0.8221\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3965 - accuracy: 0.8210\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3912 - accuracy: 0.8217\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3918 - accuracy: 0.8235\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3898 - accuracy: 0.8273s - loss: 0.3892 - accuracy: \n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3926 - accuracy: 0.8355\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3960 - accuracy: 0.8347\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3906 - accuracy: 0.8364\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3881 - accuracy: 0.8347\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3885 - accuracy: 0.8369\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3870 - accuracy: 0.8397\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3923 - accuracy: 0.8350\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3858 - accuracy: 0.8374\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3929 - accuracy: 0.8335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8b260a248>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31748,
     "status": "ok",
     "timestamp": 1586428405581,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nIyEeQdRZwgs",
    "outputId": "a0f4d9ad-9a29-41dc-b101-9e7216d74dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31746,
     "status": "ok",
     "timestamp": 1586428405581,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ci6K_r6LaF6P",
    "outputId": "09bd315f-7091-457f-b222-ce3998de57a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1545   50]\n",
      " [ 233  172]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Artificial Neural Network on test set: 85.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Accuracy of Artificial Neural Network on test set: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a single new observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Predict if the customer with the following informations will leave the bank or not:\n",
    "# Geography: France\n",
    "# Credit Score: 600\n",
    "# Gender: Male\n",
    "# Age: 40\n",
    "# Tenure: 3\n",
    "# Balance: 60000\n",
    "# Number of Products: 2\n",
    "# Has Credit Card: Yes\n",
    "# Is Active Member: Yes\n",
    "# Estimated Salary:50000\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57873591, -0.57380915, -0.52281016,  0.91241915,  0.10281024,\n",
       "        -0.69598177, -0.26422114,  0.80773656,  0.64609167,  0.97024255,\n",
       "        -0.87101922]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset to predict changed to categorical values\n",
    "new_dataset=np.array([[0,0,600,1,40,3,60000,2,1,1,50000]])\n",
    "#dataset scaled\n",
    "new_dataset=sc.transform(new_dataset)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction=ann.predict(new_dataset)\n",
    "#to get ans in true or false\n",
    "new_prediction=(new_prediction>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(new_prediction[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Approach- Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer='adam'):\n",
    "    classifier = tf.keras.models.Sequential()\n",
    "    classifier.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "    classifier.add(tf.keras.layers.Dropout(rate=0.1))    \n",
    "    classifier.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "    classifier.add(tf.keras.layers.Dropout(rate=0.1))    \n",
    "    classifier.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 fold cross validation on dataset for better accuracy\n",
    "classifier=KerasClassifier(build_fn=build_classifier, batch_size=10,nb_epoch=100)\n",
    "accuracies=cross_val_score(estimator=classifier, X=X_train, y=y_train,cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78625    0.80000001 0.80124998 0.78125    0.81625003 0.81\n",
      " 0.78750002 0.79374999 0.80124998 0.79500002]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7972500026226044\n"
     ]
    }
   ],
   "source": [
    "mean=accuracies.mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010259144536026521\n"
     ]
    }
   ],
   "source": [
    "variance=accuracies.std()\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 114us/sample - loss: 0.5501 - accuracy: 0.7550\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 85us/sample - loss: 0.5998 - accuracy: 0.7001\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 104us/sample - loss: 0.6420 - accuracy: 0.6637\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 85us/sample - loss: 0.5600 - accuracy: 0.7349\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 142us/sample - loss: 0.5818 - accuracy: 0.7142\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 190us/sample - loss: 0.7110 - accuracy: 0.5876\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 108us/sample - loss: 0.6662 - accuracy: 0.6526\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 87us/sample - loss: 0.6376 - accuracy: 0.6800\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 86us/sample - loss: 0.6202 - accuracy: 0.7603\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 109us/sample - loss: 0.5307 - accuracy: 0.7826\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 2s 244us/sample - loss: 0.7228 - accuracy: 0.5597\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 100us/sample - loss: 0.5693 - accuracy: 0.7725\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 97us/sample - loss: 0.7329 - accuracy: 0.5772\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 118us/sample - loss: 0.5154 - accuracy: 0.7875\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 140us/sample - loss: 0.6121 - accuracy: 0.7290\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 203us/sample - loss: 0.6284 - accuracy: 0.6472\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 121us/sample - loss: 0.5902 - accuracy: 0.7517\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 100us/sample - loss: 0.5313 - accuracy: 0.7962\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 99us/sample - loss: 0.5785 - accuracy: 0.7807\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 144us/sample - loss: 0.5642 - accuracy: 0.7772\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 203us/sample - loss: 0.5737 - accuracy: 0.7300\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 86us/sample - loss: 0.6298 - accuracy: 0.6650\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 87us/sample - loss: 0.5969 - accuracy: 0.7197\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 88us/sample - loss: 0.6266 - accuracy: 0.6983\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 108us/sample - loss: 0.5501 - accuracy: 0.7749\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 89us/sample - loss: 0.5361 - accuracy: 0.7903\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 88us/sample - loss: 0.5884 - accuracy: 0.7504\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 94us/sample - loss: 0.5400 - accuracy: 0.7886\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 93us/sample - loss: 0.6767 - accuracy: 0.6343\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 188us/sample - loss: 0.6593 - accuracy: 0.6425\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 103us/sample - loss: 0.5607 - accuracy: 0.7571\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 102us/sample - loss: 0.5235 - accuracy: 0.7946\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 103us/sample - loss: 0.5396 - accuracy: 0.7804\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 151us/sample - loss: 0.6184 - accuracy: 0.7460\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 206us/sample - loss: 0.6384 - accuracy: 0.6625\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 105us/sample - loss: 0.6935 - accuracy: 0.6500\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 101us/sample - loss: 0.6183 - accuracy: 0.7060\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 100us/sample - loss: 0.6037 - accuracy: 0.7156\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 99us/sample - loss: 0.6044 - accuracy: 0.7201\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 101us/sample - loss: 0.5732 - accuracy: 0.7571\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 79us/sample - loss: 0.6272 - accuracy: 0.6743\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 199us/sample - loss: 0.5660 - accuracy: 0.7443\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 122us/sample - loss: 0.6566 - accuracy: 0.6446\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 78us/sample - loss: 0.6149 - accuracy: 0.7490\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 80us/sample - loss: 0.6040 - accuracy: 0.7039\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 79us/sample - loss: 0.6264 - accuracy: 0.6946\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 78us/sample - loss: 0.6720 - accuracy: 0.6307\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 171us/sample - loss: 0.7375 - accuracy: 0.5736\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 117us/sample - loss: 0.6020 - accuracy: 0.7190\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 79us/sample - loss: 0.8370 - accuracy: 0.4660\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 119us/sample - loss: 0.6493 - accuracy: 0.6544\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 90us/sample - loss: 0.6407 - accuracy: 0.7456\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 118us/sample - loss: 0.6578 - accuracy: 0.6443\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 197us/sample - loss: 0.6058 - accuracy: 0.7857\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 91us/sample - loss: 0.5462 - accuracy: 0.7732\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 121us/sample - loss: 0.6239 - accuracy: 0.6933\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 91us/sample - loss: 0.5096 - accuracy: 0.7951\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 90us/sample - loss: 0.5711 - accuracy: 0.7458\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 92us/sample - loss: 0.5972 - accuracy: 0.7679\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 123us/sample - loss: 0.6071 - accuracy: 0.6915\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 78us/sample - loss: 0.5621 - accuracy: 0.7914\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 77us/sample - loss: 0.6138 - accuracy: 0.6668\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 157us/sample - loss: 0.6332 - accuracy: 0.6801\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 157us/sample - loss: 0.6531 - accuracy: 0.7028\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 107us/sample - loss: 0.6264 - accuracy: 0.6872\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 79us/sample - loss: 0.5630 - accuracy: 0.7494\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 77us/sample - loss: 0.5576 - accuracy: 0.7550\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 86us/sample - loss: 0.5602 - accuracy: 0.7803\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 78us/sample - loss: 0.5787 - accuracy: 0.7575\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 83us/sample - loss: 0.7391 - accuracy: 0.4943\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 2s 249us/sample - loss: 0.5325 - accuracy: 0.7785\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 97us/sample - loss: 0.6541 - accuracy: 0.6599\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 92us/sample - loss: 0.7644 - accuracy: 0.5121\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 91us/sample - loss: 0.5735 - accuracy: 0.7351\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 94us/sample - loss: 0.5169 - accuracy: 0.7937\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 194us/sample - loss: 0.5622 - accuracy: 0.7487\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 106us/sample - loss: 0.5698 - accuracy: 0.7912\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 97us/sample - loss: 0.5324 - accuracy: 0.7892\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 92us/sample - loss: 0.6053 - accuracy: 0.7175\n",
      "Train on 7200 samples\n",
      "7200/7200 [==============================] - 1s 122us/sample - loss: 0.7078 - accuracy: 0.6172\n",
      "Train on 8000 samples\n",
      "8000/8000 [==============================] - 1s 156us/sample - loss: 0.5645 - accuracy: 0.7359\n"
     ]
    }
   ],
   "source": [
    "classifier=KerasClassifier(build_fn=build_classifier)\n",
    "parameters={'batch_size':[25,32],\n",
    "           'nb_epoch':[100,500],\n",
    "           'optimizer':['adam','rmsprop']}\n",
    "grid_search=GridSearchCV(estimator=classifier,\n",
    "                         param_grid=parameters,\n",
    "                         scoring='accuracy',\n",
    "                         cv=10)\n",
    "grid_search=grid_search.fit(X_train,y_train)\n",
    "best_parameters=grid_search.best_params_\n",
    "best_Accuracy=grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 79.74%\n"
     ]
    }
   ],
   "source": [
    "print('Best Accuracy: {:.2f}%'.format(best_Accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 32, 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=best_parameters['batch_size']\n",
    "nb_epoch=best_parameters['nb_epoch']\n",
    "optimizer=best_parameters['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.6154 - accuracy: 0.7153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8b866d1c8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the above parameters to fit the training dataset\n",
    "\n",
    "tuned_classifier=KerasClassifier(build_fn=build_classifier, batch_size=batch_size,nb_epoch=nb_epoch,optimizer=optimizer)\n",
    "tuned_classifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "#run the tuned model on test dataset \n",
    "y_pred = tuned_classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Artificial Neural Network on test set: 79.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Accuracy of Artificial Neural Network on test set: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will close the Account with the Bank\n"
     ]
    }
   ],
   "source": [
    "#predicting the likely of a customer to be associated with the bank\n",
    "\n",
    "new_prediction=tuned_classifier.predict(new_dataset)\n",
    "#to get ans in true or false\n",
    "new_prediction=(new_prediction>0.5)\n",
    "if(new_prediction[0,0]):\n",
    "    print(\"Will Stay as a Customer with the Bank\")\n",
    "else:\n",
    "    print(\"Will close the Account with the Bank\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwbl0jJoa05wuIU59y39H3",
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
